# ollama

他是一个让你能通过简单命令在本地轻松下载、运行和管理大语言模型的工具，支持
CPU加速和类OPENAI 接口，适合本地部署和开发

免费的大模型
Mera Llama 羊驼
deepseek-r1:1.5b 参数的尺寸

在11434端口提供api调用